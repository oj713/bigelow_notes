---
title: "Modeling Techniques"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

* BRTs
* GLM
* Linear Regression
* Random Forest
* MaxEnt
* Artificial Neural Networks

# Linear and Logistic Regression #

* model finds best fit linear line between IV and DV
* Linear regression provides continuous output, while logistic regression is best for discrete classification output (eg. yes/no)

### Example using tidymodels ###

```{r, eval=FALSE}
example_logistic <- logistic_reg() |> set_engine("glm")

example_linear <- linear_reg() |>
  set_engine("lm") |>
  set_mode("regression")
```

### Example using motorcycle crash data ###

```{r}
mcycle <- MASS::mcycle

#examine mcycle data frame 
head(mcycle)
plot(mcycle)

#fit a linear model and plot it 
#note that se plots standard error
lm(accel ~ times, data=mcycle) |>
  termplot(partial.resid = TRUE, se = TRUE)
```

# GAMs #

https://noamross.github.io/gams-in-r-course/

GAMs are a middle ground between simple, highly interpretable models (eg. linear models) and black-box machine learning. They can model complex, nonlinear relationships but still retain clear information on the structure of their predictions.

* GAMs can fit data with **smooths/splines**, which are variably shaped functions
  * smooths are made of many smaller **basis functions**
  * the basis functions are summed together with varying weights
  * this means that a single nonlinear relationship has several parameters, creating a more complex model than something linear
  * coefficients for each variable can be extracted with the `coef()` function
  
### Example using motorcycle crash data ###

```{r}
library(mgcv)
library(ggplot2)
```

We can create a non-linear GAM model using mgcv's `gam()` function. To specify that we want to create a smooth relation between the IV and DV, we encase the DV in the `s()` function. 

```{r}
# fit the model
gam_mod <- mgcv::gam(accel ~ s(times), data=mcycle)

# plot the results
plot(gam_mod, residuals=TRUE, pch = 1)

# extract model coefficients
coef(gam_mod)
```

`coef()` tells us that the smooth for times consists of 9 basis functions, each with their own coefficient. 

### Basis Functions and Smoothing ###

* Since GAMs are so flexible, it is easy for them to become overfitted to the data. This makes smoothing important. 
  * **overfitting** is when the model is too finely tuned to noise and can't adapt well to new data 
  * **fit = likelihood - $\lambda \cdot$ wiggliness**
    * finding the right $\lambda$, or **smoothing parameter**, is key
    * GAMs can select their own smoothing parameter, be passed a specific value, or be given a method for selecting the best value. 
    * **REML: Restricted Maximum Likelihood ** method is highly recommended. 

```{r, eval=FALSE}
# Setting a fixed smoothing parameter
gam(y ~ s(x), data = dat, sp = .1)
gam(y ~ s(x, sp = 0.1), data=dat)
# Smoothing via restricted maximum likelihood
gam(y ~s(x), data = dat, method = "REML")
```

  * A higher number of basis functions can also affect wiggliness

```{r, eval=FALSE}
# Specifying number of basis functions
gam(y ~ s(x, k = 3), data = dat, method = "REML")
gam(y ~ s(x, k = 10), data = dat, method = "REML")
```

### Multivariate Regression with GAMs ###

```{r}
# retrieving example data
library(gamair)
data("mpg", package="gamair")
```

 * We can add further variables to a model by adding them into the formula with a plus sign
    * the GAM creates models for each variable and then adds them together -- hence, additive variable.

```{r}
mod_city <- gam(city.mpg ~ s(weight) + s(length) + s(price), data=mpg, method = "REML")

plot(mod_city, residuals=TRUE, pages=1)
```

* Not every variable has to be wrapped in the `s()` smoothing function -- can choose to evaluate them linearly instead
  * in practice, all continuous variables are wrapped
  * useful for categorical variables: creates a fixed effect for each level of the category

```{r}
# Introducing categorical variables
mod_city2 <- gam(city.mpg ~ s(weight) + s(length) + s(price) + fuel + drive + style, data=mpg, method = "REML")

plot(mod_city2, all.terms = TRUE, residuals=TRUE, pages = 1)
```

* **Factor-smooth interaction** : GAM formulas can also fit different smooths for different categorical variables
  * usually, also want to include a varying intercept in  case the categories are different in overall means 

```{r}
# Using factor-smooth interaction
mod_city3 <- gam(city.mpg ~ s(weight, by=drive) + s(length, by=drive) + s(price, by=drive) + drive, data=mpg, method = "REML")

plot(mod_city3, residuals=TRUE, all.terms=TRUE, pages = 2)
```

### Regression Trees ###

https://youtu.be/g9c66TUylZ4










